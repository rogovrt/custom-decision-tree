{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a7de65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "class Node:\n",
    "    '''\n",
    "    Class to define node of tree with opportunity to iterate throw\n",
    "    \n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    left_node : Node\n",
    "        Left child node\n",
    "    right_node : Node\n",
    "        Right child node\n",
    "    data : tuple\n",
    "        Data for decision tree stored in node. Feature based on what split will be performed and border value\n",
    "    ans : int\n",
    "        Answer stored in leath node\n",
    "    direction : str\n",
    "        Direction from parent node to this\n",
    "    father_node : Node\n",
    "        Parent node of one of this node\n",
    "    depth : int\n",
    "        Depth of current node in whole tree\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, direction, father_node):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        direction : str\n",
    "            Direction from parent node to this\n",
    "        father_node : Node\n",
    "            Parent node of this node\n",
    "        \"\"\"\n",
    "\n",
    "        self.left_node = None\n",
    "        self.right_node = None\n",
    "        self.data = None\n",
    "        self.ans = None\n",
    "        self.father_node = father_node\n",
    "        self.direction = direction\n",
    "        self.depth = None\n",
    "\n",
    "class SimpleTree(object):\n",
    "    '''\n",
    "    Custom class of desicion binary tree\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_depth, max_features, min_leaf_size = 1, criterion = 'entropy'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_depth : int\n",
    "            Maximum depth of tree\n",
    "        max_features : int\n",
    "            Number of features to consider for split\n",
    "        min_leaf_size : int, optional\n",
    "            Number of elements in leaf, which causes stop splitting (default is 1)\n",
    "        criterion : str, optional\n",
    "            Function to evaluate split quality (default is 'entropy')\n",
    "        \"\"\"\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf_size = min_leaf_size\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.root = None\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, direction = None, father_node = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Training sample\n",
    "        y : np.ndarray of shape (n_samples,)\n",
    "            Targer values\n",
    "        direction : str, optional\n",
    "            Direction from parent node to one, which will be created in method (default is None)\n",
    "        father_node : Node, optional\n",
    "            Parent node of one, which will be created in method (default is None)\n",
    "        \"\"\"\n",
    "        \n",
    "        cur_node = Node(direction, father_node)\n",
    "        if (direction != None) and (father_node != None):\n",
    "            cur_node.depth = cur_node.father_node.depth + 1\n",
    "            if cur_node.direction == 'r':\n",
    "                cur_node.father_node.right_node = cur_node\n",
    "            else:\n",
    "                cur_node.father_node.left_node = cur_node\n",
    "        else:\n",
    "            cur_node.depth = 1\n",
    "            self.root = cur_node\n",
    "        \n",
    "        if (len(y) == self.min_leaf_size) or (cur_node.depth == self.max_depth):\n",
    "            cur_node.ans = np.round(np.average(y))\n",
    "            return\n",
    "        \n",
    "        np.random.seed((int)(str(time.time()).split('.')[1]))\n",
    "        all_features = X.shape[1]\n",
    "        chosen_features = np.sort(np.random.permutation(all_features)[:self.max_features])\n",
    "        min_loss = np.inf\n",
    "        opt_feature = None\n",
    "        opt_t = None\n",
    "        opt_j = None\n",
    "        for ind_feature in chosen_features:\n",
    "            for j in range(X.shape[0]):\n",
    "                X_r, y_r, X_l, y_l = self.__get_parts(X, y, ind_feature, j)\n",
    "                if (len(y_r) == 0) or (len(y_l) == 0):\n",
    "                    continue\n",
    "                assert (X_l.shape[0] + X_r.shape[0] == X.shape[0]), \"Object was lost!\"\n",
    "                assert (len(y_l) + len(y_r) == len(y)), \"Object was lost!\"\n",
    "                assert ((len(y_r) != 0) and (len(y_l) != 0)), 'Ooops'\n",
    "                if (self.__loss(X_l.shape[0], X_r.shape[0], y_l, y_r) < min_loss):\n",
    "                    min_loss = self.__loss(X_l.shape[0], X_r.shape[0], y_l, y_r)\n",
    "                    opt_feature = ind_feature\n",
    "                    opt_t = X[j, ind_feature]\n",
    "                    opt_j = j\n",
    "        \n",
    "        cur_node.data = (opt_feature, opt_t)\n",
    "        X_r, y_r, X_l, y_l = self.__get_parts(X, y, opt_feature, opt_j)\n",
    "        self.fit(X_r, y_r, 'r', cur_node)\n",
    "        self.fit(X_l, y_l, 'l', cur_node)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Sample to predict results\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            array of predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        y = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__run_throw_tree(X[i, :])\n",
    "        return y\n",
    "            \n",
    "    def __loss(self, X_l_size, X_r_size, y_l, y_r):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_l_size : int\n",
    "            Number of elements in left splitter sample\n",
    "        X_r_size : int\n",
    "            Number of elements in right splitter sample\n",
    "        y_l : np.ndarray of shape (n_left_samples,)\n",
    "            Targer values of left sample\n",
    "        y_r : np.ndarray of shape (n_left_samples,)\n",
    "            Targer values of right sample\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            value of error criterion\n",
    "        '''\n",
    "        \n",
    "        return X_l_size / (X_l_size + X_r_size) * self.__H(y_l) + X_r_size / (X_l_size + X_r_size) * self.__H(y_r)\n",
    "\n",
    "    def __H(self, y):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.ndarray of shape (n_samples,)\n",
    "            Targer values of sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            value of information criterion\n",
    "        '''\n",
    "        \n",
    "        p1 = (np.count_nonzero(y)) / len(y)\n",
    "        if self.criterion == 'entropy':\n",
    "            return - p1 * math.log2(1e-7 + p1) - (1 - p1) * math.log2(1e-7 + 1 - p1)\n",
    "        if self.criterion == 'gini':\n",
    "            return p1 * (1 - p1) + (1 - p1) * p1\n",
    "    \n",
    "    def __get_parts(self, X, y, ind_feature, j):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Sample to split\n",
    "        y : np.ndarray of shape (n_samples,)\n",
    "            Targer values to split\n",
    "        ind_feature : int\n",
    "            Index of feature based on which split will be performed\n",
    "        j : int\n",
    "            Index of element in column which will be splitter\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray of shape (n_right_samples, n_targets)\n",
    "            Right splitted sample\n",
    "        np.ndarray of shape (n_riht_samples,)\n",
    "            Targer values of right sample\n",
    "        np.ndarray of shape (n_left_samples, n_targets)\n",
    "            Left splitted sample\n",
    "        np.ndarray of shape (n_left_samples,)\n",
    "            Targer values of left sample\n",
    "        '''\n",
    "        \n",
    "        X_r = X[X[:, ind_feature] <= X[j, ind_feature], :]\n",
    "        y_r = y[X[:, ind_feature] <= X[j, ind_feature]]\n",
    "        X_l = X[X[:, ind_feature] > X[j, ind_feature], :]\n",
    "        y_l = y[X[:, ind_feature] > X[j, ind_feature]]\n",
    "        return X_r, y_r, X_l, y_l\n",
    "    \n",
    "    def __run_throw_tree(self, x):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray of shape (n_features)\n",
    "            Features of one fixed object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Target variable for given objest\n",
    "        '''\n",
    "        \n",
    "        cur_node = self.root\n",
    "        while (cur_node.ans == None):\n",
    "            if (x[cur_node.data[0]] <= cur_node.data[1]):\n",
    "                cur_node = cur_node.right_node\n",
    "            else:\n",
    "                cur_node = cur_node.left_node\n",
    "        return cur_node.ans\n",
    "\n",
    "def print_scores(test, pred):\n",
    "    print(accuracy_score(test, pred))\n",
    "    print(f1_score(test, pred))\n",
    "    print(roc_auc_score(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3ee7824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9743589743589743\n",
      "0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# code for simple check of ideas on Fisher's iris dataset\n",
    "\n",
    "iris = load_iris()\n",
    "data_bin = iris.data[:100, :]\n",
    "target_bin = iris.target[:100]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_bin, target_bin, test_size=0.8)\n",
    "iris_tree = SimpleTree(max_depth = 3, max_features = (int)(X_train.shape[1] / 2), criterion = 'gini')\n",
    "iris_tree.fit(X_train, y_train)\n",
    "y_pred = iris_tree.predict(X_test)\n",
    "print_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a3b544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786116322701689\n",
      "0.9714285714285715\n",
      "0.9825087688594285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data was get from https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+\n",
    "\n",
    "train_data = pd.read_csv(\"./test_data/datatraining.txt\", sep=\",\")\n",
    "test_data = pd.read_csv(\"./test_data/datatest.txt\", sep=\",\")\n",
    "train_data = train_data.drop(['date'], axis = 1)\n",
    "test_data = test_data.drop(['date'], axis = 1)\n",
    "\n",
    "# results with entropy criterion\n",
    "\n",
    "occ_tree = SimpleTree(max_depth = 3, max_features = train_data.shape[1] - 1)\n",
    "occ_tree.fit(train_data.drop(['Occupancy'], axis=1).to_numpy(), train_data['Occupancy'].to_numpy())\n",
    "occ_test_data = test_data.drop(['Occupancy'], axis=1).to_numpy()\n",
    "occ_test_target = test_data['Occupancy'].to_numpy()\n",
    "prediction = occ_tree.predict(occ_test_data)\n",
    "print_scores(occ_test_target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf819ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782363977485928\n",
      "0.9708835341365462\n",
      "0.9817752960021779\n"
     ]
    }
   ],
   "source": [
    "# results with gini criterion\n",
    "\n",
    "occ_tree_gini = SimpleTree(max_depth = 3, max_features = train_data.shape[1] - 1, criterion = 'gini')\n",
    "occ_tree_gini.fit(train_data.drop(['Occupancy'], axis=1).to_numpy(), train_data['Occupancy'].to_numpy())\n",
    "prediction_gini = occ_tree_gini.predict(occ_test_data)\n",
    "print_scores(occ_test_target, prediction_gini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
